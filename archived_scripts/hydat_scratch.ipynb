{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from pykalman import KalmanFilter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: bunch of memory duplication, but this is a notebook. don't convert to .py yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_stations = pd.read_csv('./index_data/bc_hydro_stations.csv', sep=' \\t', engine='python')\n",
    "# we'll need some kind of entity resolution to cut down to reservoirs -> choose resolve stations to reservoirs (leg work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_stations(df, stations):\n",
    "    \"\"\"\n",
    "        Return only data with a station in stations\n",
    "    \"\"\"\n",
    "    return df[df['STATION_NUMBER'].isin(stations)][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_annual_averages(df, station_no):\n",
    "    \"\"\"\n",
    "        lazy visual for annual - double check if we have weird outliers\n",
    "    \"\"\"\n",
    "    station = df[df['STATION_NUMBER'] == station_no]\n",
    "    fitline = linregress(station['YEAR'], station['MEAN'])\n",
    "    # linregress val is pretty meaningless, but mostly there for context\n",
    "    plt.plot(station['YEAR'], station['MEAN'])\n",
    "    plt.plot(station['YEAR'], fitline.intercept + station['YEAR']*fitline.slope )\n",
    "    \n",
    "    plt.show()\n",
    "#     return annual_linregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_values(df, kalman_smoothed):\n",
    "    \"\"\"\n",
    "        visualize basic model regresssions\n",
    "    \"\"\"\n",
    "    loess_smoothed = lowess(df['value'], df['date'], frac=0.03, is_sorted=False)\n",
    "    # again, this is mostly visual\n",
    "    plt.figure(figsize=(50, 20))\n",
    "    plt.plot(df['date'], df['value'], 'b.', alpha=0.5)\n",
    "    plt.plot(df['date'], loess_smoothed[:, 1], 'r-')\n",
    "    plt.plot(df['date'], kalman_smoothed[:, 0], 'g-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stations_daily_data(conn, stations):\n",
    "    #only works for single station now, later groupby\n",
    "    stations_str = str(stations)[1:-1]\n",
    "    LEVELS = ['LEVEL{}'.format(dayno) for dayno in range(1,32)]\n",
    "    query = \"SELECT {levels} FROM DLY_LEVELS WHERE STATION_NUMBER IN ({stations})\".format(levels=LEVELS, stations=stations_str)\n",
    "    print(query)\n",
    "    unparsed_data = pd.read_sql_query(daily_levels_query, conn)\n",
    "    return unparsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see http://collaboration.cmc.ec.gc.ca/cmc/hydrometrics/www/HYDAT_Definition_EN.pdf for HYDAT schema\n",
    "db_filename = './data/Hydat.sqlite3'\n",
    "conn = sqlite3.connect(db_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_query = \"SELECT * FROM `ANNUAL_STATISTICS` WHERE `DATA_TYPE` = 'H';\"\n",
    "good_annual_stations_query = \"\"\"SELECT STATION_NUMBER\n",
    "                                FROM ANNUAL_STATISTICS \n",
    "                                WHERE DATA_TYPE = 'H'\n",
    "                                    AND MEAN IS NOT NULL\n",
    "                                GROUP BY STATION_NUMBER\n",
    "                                HAVING COUNT(*) > 10;\"\"\"\n",
    "bc_stations_str = str(list(bc_stations['Station Number']))[1:-1]\n",
    "daily_levels_query = \"SELECT * FROM DLY_LEVELS WHERE STATION_NUMBER IN ({stations})\".format(stations=bc_stations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_data = pd.read_sql_query(annual_query,conn) #anual statistics levels table\n",
    "good_stations = pd.read_sql_query(good_annual_stations_query, conn) # stations with 'enough' data (>10 avg years)\n",
    "daily_data = pd.read_sql_query(daily_levels_query, conn)#.set_index(['STATION_NUMBER','YEAR', 'MONTH']) # stations with 'enough' data (>10 avg years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_annual_data = filter_by_stations(annual_data, good_stations['STATION_NUMBER']).dropna(subset=['MEAN'])\n",
    "# stations w/enough years, remove years w/bananas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for station_no in good_stations['STATION_NUMBER']:\n",
    "#     plot_annual_averages(cleaned_annual_data, station_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01AD004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01AK003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01AO002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01AO003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01AO004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01AO010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01AO011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01AP003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01AP005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01AQ007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01AR009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01AR010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01AR013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01BD008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01ED006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>02AB008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>02AB014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>02AB017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>02AB018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>02AD007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>02AD010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>02BA004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>02BA005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>02BA006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>02BB004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>02BD004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>02BD005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>02BF001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>02BF002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>02BF004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>08NM083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>08NM084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>08NM113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>08NM131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>08NM132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>08NM143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>08NM243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>08NN014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>08PA009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>09AA001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>09AA004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>09AA017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>09AB001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>09AB004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>09AB010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>09AC005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>09AE002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>09CA001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>09DC004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>09DC005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>10ED007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>10JA002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>10JE002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>10LC002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>10PA002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>10PB003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>10PC005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>10QC003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>10RA001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11AE013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    STATION_NUMBER\n",
       "0          01AD004\n",
       "1          01AK003\n",
       "2          01AO002\n",
       "3          01AO003\n",
       "4          01AO004\n",
       "5          01AO010\n",
       "6          01AO011\n",
       "7          01AP003\n",
       "8          01AP005\n",
       "9          01AQ007\n",
       "10         01AR009\n",
       "11         01AR010\n",
       "12         01AR013\n",
       "13         01BD008\n",
       "14         01ED006\n",
       "15         02AB008\n",
       "16         02AB014\n",
       "17         02AB017\n",
       "18         02AB018\n",
       "19         02AD007\n",
       "20         02AD010\n",
       "21         02BA004\n",
       "22         02BA005\n",
       "23         02BA006\n",
       "24         02BB004\n",
       "25         02BD004\n",
       "26         02BD005\n",
       "27         02BF001\n",
       "28         02BF002\n",
       "29         02BF004\n",
       "..             ...\n",
       "727        08NM083\n",
       "728        08NM084\n",
       "729        08NM113\n",
       "730        08NM131\n",
       "731        08NM132\n",
       "732        08NM143\n",
       "733        08NM243\n",
       "734        08NN014\n",
       "735        08PA009\n",
       "736        09AA001\n",
       "737        09AA004\n",
       "738        09AA017\n",
       "739        09AB001\n",
       "740        09AB004\n",
       "741        09AB010\n",
       "742        09AC005\n",
       "743        09AE002\n",
       "744        09CA001\n",
       "745        09DC004\n",
       "746        09DC005\n",
       "747        10ED007\n",
       "748        10JA002\n",
       "749        10JE002\n",
       "750        10LC002\n",
       "751        10PA002\n",
       "752        10PB003\n",
       "753        10PC005\n",
       "754        10QC003\n",
       "755        10RA001\n",
       "756        11AE013\n",
       "\n",
       "[757 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_station = '08GA079' # COQUITLAM LAKE FOREBAY\n",
    "plot_annual_averages(cleaned_annual_data, my_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data\n",
    "# look at max/min later on for outlier-checking or to better inform\n",
    "# Later, try Kalman filter w/weather... nulls in Kalman\n",
    "# there is a fullmonth and no-days tag - maybe take advantage if gapped data is too hard\n",
    "# ignoring symbols, check later to see if important (may account for inaccuracies)\n",
    "# they gives us precision (in m, to cm or mm), ignoring for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_day_data = filter_by_stations(daily_data, [my_station])#daily_data.loc[[my_station]]\n",
    "melted_day_data = station_day_data.melt(id_vars = ['YEAR', 'MONTH'], value_vars=LEVELS).dropna()\n",
    "melted_day_data['date'] = pd.to_datetime(melted_day_data['YEAR'].map(str) + '-' + melted_day_data['MONTH'].map(str)+ '-' + melted_day_data['variable'].str[5:])\n",
    "melted_day_data.set_index('date', inplace=True)\n",
    "melted_day_data.sort_index(inplace=True)\n",
    "melted_day_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = melted_day_data[:]\n",
    "df['date'] = df['date'].astype(np.int64) // 1e9 # convert dates to time\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kalman_data = df[['value', 'date']]\n",
    "initial_state = kalman_data.iloc[0]\n",
    "observation_covariance = np.diag([1, 0.01]) ** 2\n",
    "transition_covariance = np.diag([0.5, 0.02]) ** 2\n",
    "transition = [[1, 0], [0, 1]]\n",
    "# work out the proper values later. add weather to this later on - will inform precip\n",
    "\n",
    "kf = KalmanFilter(initial_state_mean=initial_state,\n",
    "                  observation_covariance=observation_covariance,\n",
    "                  transition_covariance=transition_covariance,\n",
    "                  transition_matrices=transition)\n",
    "kalman_smoothed, _ = kf.smooth(kalman_data)\n",
    "\n",
    "plot_daily_values(df, kalman_smoothed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT S.*, D.YEAR_FROM, D.YEAR_TO, D.RECORD_LENGTH FROM\n",
    "# (SELECT STATION_NUMBER, STATION_NAME, LATITUDE, LONGITUDE, DRAINAGE_AREA_GROSS FROM STATIONS WHERE STATIONS.PROV_TERR_STATE_LOC='BC') S\n",
    "# INNER JOIN\n",
    "# (SELECT STATION_NUMBER, YEAR_FROM, YEAR_TO, RECORD_LENGTH FROM STN_DATA_RANGE WHERE DATA_TYPE = 'H' AND YEAR_FROM <= 1990 AND YEAR_TO >= 2015 AND RECORD_LENGTH>5) D\n",
    "# ON S.STATION_NUMBER = D.STATION_NUMBER;\n",
    "# -> need to look at data and filter \n",
    "\n",
    "# annual_query = \"SELECT * FROM `ANNUAL_STATISTICS` WHERE `DATA_TYPE` = 'H';\"\n",
    "# good_annual_stations_query = \"\"\"SELECT STATION_NUMBER\n",
    "#                                 FROM ANNUAL_STATISTICS \n",
    "#                                 WHERE DATA_TYPE = 'H'\n",
    "#                                     AND MEAN IS NOT NULL\n",
    "#                                 GROUP BY STATION_NUMBER\n",
    "#                                 HAVING COUNT(*) > 10;\"\"\"\n",
    "# bc_stations_str = str(list(bc_stations['Station Number']))[1:-1]\n",
    "# daily_levels_query = \"SELECT * FROM DLY_LEVELS WHERE STATION_NUMBER IN ({stations})\".format(stations=bc_stations_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
